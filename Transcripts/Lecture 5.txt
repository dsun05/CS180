Okay, so to start today, we're going to discuss representing graphs. So there are multiple ways to represent graphs, and you guys have covered a couple of them, right? So the first kind of like standard or obvious way is just like how we define graphs, right? A graph is a set of vertices and edges, and so if I just simply give you the list of the vertices and then the list of the edges, I've defined a graph. And the other way we've covered is just for the simple diagram, right? So if I had a graph, I'm just going to draw some random graph. A, B, C, let's put D here, maybe there's some node e over here that doesn't have any edges. Right, so this is another way to represent a graph, but now we're going to cover two new ways to represent a graph that are going to be useful for the algorithm we're using. So the first representation of a graph is what we call the adjacency matrix of the graph. Okay, so what is an adjacency matrix of a graph? Well, as the name suggests, it's an n by n matrix A. And here we're going to use the notation that n is the size of v, the number of vertices in the graph. Okay, so we have this n by n matrix A, and what it's gonna be is it's gonna basically record where all the edges are. So the matrix at, let's do i and j, so at the i-th row and the j-th column, is going to be 1 if v_i, v_j is an edge in the graph. So, let's say, is an edge in the graph G, and similarly it's going to be zero if vi, vj is not an edge in G. So basically if we look at this above example here, I can make a matrix. Try to fit it so you can see it all right. So let's make it a little bigger. Okay, so what I'm going to do now, this would go away. You can see the graph. Okay, so basically what we'll do is we'll have, because there's one, two, three, four, five vertices, it's going to be a five by five matrix, and we're gonna, I'm just gonna annotate the rows and the columns. So this first row, I'm just gonna go in order, so the rows are gonna correspond to the vertices, and so will the columns. And the first thing to note is that because we're only considering graphs where there are no edges between a vertex in itself, right? There's no edge here between A, like from A to A. So every entry on the main diagonal here, which basically represents like A to A, and if there's an edge between A and A, is going to be zero. Okay, and now basically let's go start filling this in. So A and B, right, is there an edge between A and B? Yes, there is. And similarly there's an edge between B and A, same edge. And then we can continue. Is there an edge between A and C. Yes, there is. So, it's a 1 here. Similarly, this way. Is there an edge between A and D? No. So, 0. And a 0 here. And so forth, right? So, there's no edge between A and E. So, we put a 0 here. Now we're looking at B and C. There is indeed an edge. B and D, there's no edge, so we put zeros. And B and E, there's again no edge, so we get zeros. Okay, now we filled out C and C already. Now the question is C and D. There is an edge. Okay, now... Oh yeah, there's a question. What's your answer? Sorry, I didn't care for my. Oh, okay. So C and D there was an edge. D and C, there's an edge. Let's finish this off. C and E, there was no edge. Okay, D and D, there's an edge. We put that, or sorry, there's no edge between D and E. That's the main diagonal, but now D and E, there's again no edge, and no edge. Okay, so you excuse my inability to draw a square matrix. What you'll notice, Okay, what you'll notice is that this matrix is, A is what's called a symmetric matrix. And what that means is basically, across the main diagonal, it's mirrored. Right? So, basically what this means is that A i j is equal to a j i and this is true because by definition a i j is one if there's an edge between vertex i and vertex j and in our graph right if there's an edge between two vertices there's an edge between them in the you know the opposite direction too right an edge between a and c is the same as an edge between c and a Okay, so this is one way to represent graphs that will be useful. And now we're going to look at one more way to represent graphs that's called the adjacency list. Okay, so an adjacency list is similar to an adjacency matrix, except instead of keeping, like, this entire matrix, you're going to instead keep a set of n lists, one for each vertex, right? So there's going to be a set of n lists. I'll call them L sub, let's say, V for every V in the vertex set. And now, LV is going to be a linked list containing all the neighbors of V. Right, so this is another way to represent the graph. Basically, I just give you the list of, you know, where all the edges are. So, for example, we look at our graph again. I wonder if there's a way I can copy this. Okay, so we can see it again here. Okay, perfect. So if I want to give a, like, the linked list representation of this graph, well, we're going to have five lists, one for each vertex. So L A, right, is the set B, C. Right, because there's edges between B and C, from A, nothing else. Similarly, LB is A, C. And we can just fill this out in a similar manner, right? LC is gonna be A, B, D. Ld is just C. And Le is the empty set. So there's no edges from E. Okay, so hopefully this is clear, these two different ways to represent graphs. They're going to be useful in our algorithms. And so one just note on notation, right, so we're using n to be number of vertices. and we're going to use m to denote the number of edges. And one thing you'll know, you'll notice, is that m is upper bounded by n choose 2. Right, that's the maximum number of edges you can have in the graph because that is enough, like, basically the count of every pair you could pick, and that would mean there's an edge between every single pair of vertices in the graph. And this, just to remember, is n minus one over two, which is O of f squared. Okay, and then One other thing that's useful. To notice is what is the size? Of this adjacency list representation. Right, so what is the size? Okay, well, if it's represented as a linked list, like n-linked lists, well, it has to be at least n, right, because we have to have n-linked lists. So there's n, yeah, so it's n, there's n-linked lists, and then what is the size of each list? Well, the size of LV is equal to the degree of the vertex V in the graph, right? It's the number of edges coming out from V. And one fact that's useful, right, is if we sum over all the vertices in the graph, the degree of d. Does anyone have any idea what this is equal to? Okay, yeah, someone said it in the chat, it looks like. Yeah, so it's equal to 2m. And why is this? Well, I mean, it's basically because every edge is going to contribute to this sum twice. All right, so since every edge contributes twice, right, if I have an edge between vertices a and b, right, like say this edge, then it gets added into the sum, right, it contributes to the sum when we're summing it for vertex A and also again for vertex B. So, what that means to answer the size of the adjacency list representation is, well, there's n linked lists, right, that's like the the pointers to the heads of the n linked lists, and then the total size of these linked lists is at most 2m. So basically what that means is the total size is going to be O of n plus m. Okay, so now I'm just going to do a quick table to compare the adjacency matrix versus adjacency list representation. So here. So we have representation size. And then we have a couple other properties. So determine if some edge is in the graph and finally find all neighbors of some vertex V. So these are some things we would potentially be interested in. We're just going to cover the time complexity of these different things will be useful in the algorithms we use. So we already did this one, the representation size of the adjacency list. We just did that. That is O of n plus m. And can anyone tell me what the representation size of the adjacency matrix is? Right, so again in the chat, it's going to be n squared. Right, if we look at it, it's an n by n matrix. Each entry is a bit, so yeah, it's taking n squared. It's n squared entries, so just write O of n squared. Okay, now what about determining if an edge is in the graph? Let's just do the adjacency matrix. Any ideas? Yeah, constant, O of 1. Right, why is it constant? Well, if I just simply look at the entry A at UV, right? So, like, if I wanted to know, is there an edge between A and E in the graph in this representation? I just look at either this entry, A, E, or this entry, and it's zero, so I know no, and since I'm just looking at one entry, it's O at one time. What about the adjacency list? How long do you think it would take to determine if an edge is in the graph? Okay. I'm not seeing any answers yet. This one is a little bit trickier. Okay, so there's an answer O of M. So M is the total number of edges, right? So that would mean I went through, that's like the size of the entire link list. actually I'm gonna argue there's like a slightly cleverer way to determine. So again, what if I let's pick two different verses, let's say B and D. What if I wanted to tell if they were like check if there was an edge between B and D, how How would I go about it here? Check the shorter list, B or D. Yeah, exactly. So basically you pick a list, B or D, and then you go through it and you see, was like, so for example, let's pick B. You look at LB and you check, is D in LB? Or you could have equivalently picked D, looked at LD and checked, is B in LD? Now, if you know one of the lists is shorter than the other, yeah, you can optimize a little bit that way. For now, I'm just going to say the complexity of this is O of the degree of U. I'm just gonna, like, or, okay, or it can be O of the degree of V, right, one of the endpoints. Yeah, so that was exactly correct, right? You pick an endpoint, you go through that list, it takes uh time proportional to the degree of that vertex to go through the list. Okay and then the final thing in the table find all neighbors of v. How long do we think it takes in the adjacency matrix representation? So let's go back up. Let's look at it. Here's an adjacent matrix representation, and I want to find all the neighbors of A, say. Yeah, exactly. In the chat, it's O of N, right? Why is it O of N? how would I do this? Say, okay, I want to find all the neighbors of A. That's given by this row, or equivalently this column. You can't see what I'm pointing with my pen. So this row, or this column. So what would we do? We would just, you know, let's let's take this row. We would iterate through it, and we would keep track of where the ones were. And to iterate through this entire row takes O of n pi. Okay. And how about in the adjacency list to find all the neighbors of a vertex v? >> Degree of V? >> Right, yeah, of degree V. Right, it's basically the same thing as how we determined if an edge was in the graph. Right, so given the adjacency list representation, I want to find all the neighbors of V. So let's say C. I want to find all the neighbors of C. Well, I just look at LC and I iterate through it. And that takes time proportional to the degree of C. So what you'll notice, right, is there's various tradeoffs in these representations. So the adjacency list is going to be more compact, especially if the graph is sparse, like if there aren't that many edges. At most, m can be n squared, but-- of n squared, but there could be far fewer edges. And in that case, the adjacency list representation will be more compact. However, the adjacency matrix representation is very fast at determining if an edge is in the graph. Just go to the entry in the matrix, and you're done. However, for finding all neighbors, again, the adjacency list representation is more efficient, because you have the list right there. You can just iterate. You don't have to waste time effectively looking at the entries of the matrix that were zeros. That's what's taking the time in the adjacency matrix representation, like the extra time. OK, so I think we're basically going to mainly be using the adjacency list representation throughout the rest of this lecture, but it's important to keep in mind the adjacency matrix. It might come up later in the course, not entirely sure. OK. So now, one more thing I just want to point out. I believe you defined what a connected graph was previously, but g connected means there's a path between u and v for all vertices in the graph. Okay, and basically, if g is connected, m, the number of edges has to be greater than or equal to n minus 1. Does anyone have like a quick explanation for why that's the case? Yeah, yeah, it was said in the chat, right? So n minus one is each vertex having one neighbor in a line, right? Which is the minimum you would need to connect, right? So if you had two vertices, I would need one to connect them. If I added a third vertex, I need to add at least one more edge, right? So you can basically prove this by induction, right? like every new vertex I add I must add at least one more edge to connect it to my graph. And therefore you get n minus one. Right, so you would just simply prove it it's like base case. Um well you can even have a base case being uh like one node you can say one vertex graph zero edges. It's technically connected, right? There's a path between all pairs of vertices because there aren't even any pairs of vertices, and then basically the argument in the chat showed the inductive step. Right, so if G prime is a connected graph with n vertices and m greater than or equal to n minus 1 edges. It was actually called, let's just call this one G. Now, right, so, okay, let me just make it clear what I'm doing. I'm saying, by By inductive step, I mean assume the statement holds for n, and then that implies it holds for the n plus 1 case, right? So first number of vertices, right? And so let me just-- so that's what I'm doing here, right? So I'm saying if g is a connected graph with n vertices and m is greater than or equal to n minus 1 edges, right? That's the like-- that's the assumption that holds for m. And now we're just going to add a new node. Now consider-- yeah, basically consider-- I mean, OK, this is just a sketch, but consider adding a new vertex. This requires adding at least one new edge to connect v to g. Okay, and so what this means is that, so what we can infer from this, right, is if G is connected, m plus n is O(m). Right, basically, because m is at least n minus 1, this n term can just be bounded by m. Okay, so this is just useful for thinking about the complexity of algorithms we'll consider, right? So, mainly we'll be considering connected graphs. They're very common. Otherwise, you or you'll have a graph with, you know, multiple connected components, but it's not super common to consider a graph like the one I drew here where it's just like a vertex just sitting out there all by itself. Okay, and now before we get back to the search algorithms, just going to briefly review two data structures that will be useful. So, I did not spell that correctly, queues and stacks. Right, so a queue, I'm assuming this is already known, so I'm just gonna quickly review it. So a queue is what we call a first in, first out data structure. Right, and basically you can push elements onto the queue, and you can pop them off the queue. And I draw like a diagram. When you push elements onto the cue, you go like this. You're putting the elements onto the cue from the back here, and then when you pop them off, you take them from the front. So when you pop, you pop off A first, then you would pop off B, etc. That's why it's called first in, first out, right? Because the first thing you pushed onto the cue was A, the first thing you pop off is also A. And in contrast, a stack is last in, first out. Right, so again, same operations. push and pop. But now, when we push elements onto the stack, right, it's like, as the name suggests, it's like an actual stack. So, we, you know, we would push A on, and then we We push B on, C, D, et cetera. And now when we pop, right, when we pop, we first pop D, then we pop C, B, A, right? So the first thing we pushed, which was A, is the last thing to be popped, and the last thing we pushed in was D, it's the first thing to be popped. That's why it's called a last in first out. Okay, so now that we've covered how to represent graphs and discussed queues and stacks, we're gonna return to something that was allegedly covered last time, which was that first search. And we're going to, so I was told that you covered the algorithm and its correctness last time, and this time we're going to go over the time complexity analysis. Okay, good. So I'm actually going to slightly, I'm going to rewrite the algorithm, and I'm going to define it slightly differently than was done last time, in that I'm going to define it using a Q. Let's just say "using Q". Okay. So, breadth-research-algorithm, it's given a graph G. We're gonna assume, I mean, the graph can be given in, in like adjacency list form, say. But I'm still gonna use this notation because writing the lists is super annoying. But just know So, like, notationally, when you see a graph given as an input to an algorithm, it's going to be represented in either adjacency matrix, adjacency list form, something like that. It's not like a computer can be given as input like a diagram. But we just use this as shorthand. And so, how does the algorithm go? So first we're going to initialize a Q, a capital Q, and then push S onto the Q. All right, so this is just like starting state. S is the start node for our search. And now we're going to also initialize an n-sized array that we'll use, that we'll call discovered. with, you know, all entries set to false. Okay, now we're gonna set discovered at s to be true. Okay, so this is like the setup portion of the algorithm. We have our queue, s is on it, it's the starting thing, and s has been discovered. And now we're gonna do the like loop part of the algorithm, right? So, while l, not l, what was the list? While q is non-empty. So, while q is not empty, what do we do? We first pop some vertex V off cue, and then And then for every edge, V, W, connected to V. So for every edge from V, if this is a node we haven't already discovered, right? If discovered at w is false, then we're going to push w onto q and set discovered at w true. Let's just clear this is a if statement, and then the for statement is, again, this stuff. Okay, so hopefully this is the entire algorithm. Hopefully it's clear what it's doing, and I'm going to argue it's exactly the same as the previous version of breadth-first search. So, in the previous version of breadth-first search, you had like layers that you discovered, right? So you would start with S, you would push, or rather you would create a list of everything incident to S. That was like layer one. Then you would go through that layer, and everything incident to the vertices in that layer that you had not already discovered, you would put in layer two, and you would keep proceeding until you didn't have anything more add. And what you'll notice is when you run this algorithm, right, well, what happens with the Q in this algorithm? Well, you start with S on the Q. So let's look at the Q. So you start with S, and this is layer 0. It's like your starting vertex. And then what are you going to do in the first iteration of the while loop? You're going to pop S off the queue. And then for everything incident to S, you're going to make them discovered. You're going to push them onto the queue. So what ends up happening, actually, is you're going to push a bunch of these vertices. And this is actually just layer 1, same thing as the previous algorithm. Now you're going to push off something from layer 1. You're going to go through it again. You're going to push on more things. And what you'll notice is, by the nature of the queue, you're going to, in order, pop off all of layer 1 and push on anything incident to those nodes haven't already discovered, which is layer 2. So basically, this queue formulation is just an equivalent description of breadth-first search. And this is one way you would implement it as an algorithm. You would, instead of keeping track of all these different lists, you can just use a single queue. Okay, so now, does anyone have any idea about the runtime of breadth-first search or maybe just an idea as to how we would analyze the runtime? Okay, I see O of N in the chat. So, okay, well, one of the issues here is that it's a, you kind of need like an explanation and analysis. So maybe I should have, I mean, okay. So decent, it's a decent guess, but let's go, maybe I'll break the question to the smaller steps. So first there's some, So we're going to do time complexity BFS. And OK, here we go. So first, we're going to initialize a queue, push s onto the queue. That's just like a constant time. Now we're going to initialize an n-sized array, right? This step takes O(n) time. Now we're going to set discover to true. That takes O(1) time. Okay, so this is like the pre-processing or the setup phase. Okay, so now the real, the challenge is to analyze this, this while loop. So the first thing we can notice when we look at the while loop is, let's see, I think everything inside is constant time, right? Popping a vertex to the off cue, constant time. Like each of the core operations discovered is false, that's constant, pushing is constant, and setting discovered it true is constant, right? Each of these, each of these core operations is constant, and checking if this, right, but now this is the question. What is the time complexity here, right? So, what's the time complexity here? And And then we have to argue how many times will we actually loop, right? So how many times do we execute the while loop? So can anyone tell me what the time complexity of this step is here, this B? We covered this earlier with the-- when we were doing the representations of the graphs, right? How long does it take to go through every edge in a graph, like determine all the edges off of a, not in the graph, off connected to V? So how long does it take to go up? Isn't it like two arm? Yeah, yeah, okay, you may be going ahead a little bit, but um, so to define all the neighbors of V is in the adjacency list was here right it's O of degree of V right so this this is O of V right yes if we have the graph in adjacency list representation which which we do we just you know look at the link list for V and go through it and see. So this is going to be gone through O of degree V times. But now we need to somehow analyze this whole thing together. And the way to analyze that is we have to argue, we have to argue how many times is this while loop going to be run. So first of all, I claim it's not going to run forever. It could be the case that we keep popping vertices off of Q, we keep pushing more things onto Q, it never terminates. So why must it terminate? Well, if you look at the algorithm, when do we push things onto Q? We push things onto Q down here in this step. Right? And this is, from the "if" statement before, only executed if w not already discovered. Right? And immediately after we push w on, we set it to discovered. So, what that means, right, so maybe I'll just write this down here, each vertex v can only be pushed onto the queue once. Right? Because whenever we push some vertex onto the queue, we immediately set it to discovered, and then it'll never be the case that this if we'll execute again, because discovered will not be false. So, we will never, we will never push that same vertex back onto the queue. Right. So, now, once we figure this out, we know that, switch back to blue, to this while loop will be executed at most n times. Because if we're only gonna push, like the most times we could run the while loop is where we push every single vertex on to the queue once. and then we would execute it n times to pop it off, pop off each vertex in the graph. Okay, so now let's maybe just write this explanation here. So each vertex v can only be pushed onto the queue once. So the while loop will be executed. at most, and times. And now from our analysis previously, each execution of the while loop, right, right, takes O of degree of V plus O1 time, right? This step took O1 time. This for loop was executed O of degree of V times, with the subsequent steps being constant. And so what that means is the total while loop execution time is given by summing over each vertex v in the graph, one for each execution of the while loop, and each one took-- Well, it technically took degree of v time, but plus o of 1. And then we saw this before, right? This was equal to-- the sum of all the degrees in the graph was 2m. And then this o of 1 term was summing over all vertices, so it's o of n. And then the setup time, right, the steps before the while loop, we go back up. That was, you know, some constant steps and an O of N step. So that took O of N time. And so what we get is the total time of breadth-first search, which is the sum of these two things, is going to be O of M plus N. Okay, there was a question in the chat. Do we need to generalize O of degree of V to like an average or worst case scenario? Yeah, okay. So, this analysis was doing like the average case scenario or like it was actually calculating That's how you get m. I could get a worse bound, right? So how could I have alternatively analyzed the time complexity of this? I could have said, well, there are, you know, at most n executions of the while loop, and each execution takes, you know, at most n time, O of n time, because there are at most n O of n neighbors of v. and then I would just say, okay, so this thing is upper bounded by O of n squared. But O of n squared is a worse bound than O of n plus m, and the reason we got this better bound is instead of just saying, oh, you know, in the worst case there's n neighbors of some vertex v, we're saying, no, the actual number of neighbors of a vertex v is degree v, and when we sum, because we're summing over every vertex in the graph, we know the sum of all the degrees of all the vertices is two times the number of edges. Right, so this is where there are multiple ways to get a bound, and you always want to try to get the best bound you can get. Right, I mean, we can always, you know, we can always upper bound any algorithm by, you know, like million, million, million, like some huge, you know, exponential thing. That's not super interesting. So what we're trying to get is what's called the tightest bound you can get. And in this case it's O(m+n). And I had a quick question. So at the end this queue is going to empty out, right? Yes. And should we prove that or... Oh, yeah, yeah, yeah. I guess I didn't write it, but I said it, right? I proved that the algorithm would terminate, right? And so, okay, I'll just write it here. So why... What is happening here? That's not great. So why is breadth-first search... So, sorry, what was your question? Why does breadth-first search terminate, right? Yeah, hmm, but basically like should we write that or not for our... Yeah, yeah, yeah, you need to argue... So, okay, I thought last time you had argued correctness of the algorithm, but when you argue correctness you need to argue that it's gonna terminate also. And so, why does it terminate? Right, the reason it terminates is because how many times can this while lib be executed, right? It can be executed at most n times because we never push, you know, a node onto this queue twice. Right? We wrote over here. Yeah. Yeah, so. Since, yeah, since we only push a node onto the queue at most once, Yeah, the while loop can execute at most n times. And once that's done, the algorithm terminates because there's no more loops. Got it. Thank you. Yeah. Okay. I think we're going to take a quick break here. And when we get back, we're going to go over an alternative kind of search called depth first search. So how about we take like a 10-minute break and come back at 2.15. I'm sorry I'm on Eastern Time, I guess 11.15. Okay, so yeah, so now in contrast to breadth-first search, we're going to cover another search algorithm called depth-first search. And so breadth-first search, right, we took, we started with our initial node S. We kind you know, we went to all the neighbors, we looked at them, once we'd done that, that was like the first layer, we went to like all the neighbors of those neighbors, that's like layer two and so forth, right? So we traverse the graph in a breadth-first manner, right? We, you know, you go layer by layer. In contrast, in depth-first search, I mean, it's still a search algorithm, and we're still going to find any nodes connected to our starting node. But our traversal method is going to be different. So what we're going to do instead is we're just going to continue down a path till we can't continue anymore. And once we reach a dead end, then we backtrack, continue down another path, et cetera. So the basic, I guess, idea behind depth It's, you know, just follow a path in the graph until you reach a dead end. And then backtrack. Backtrack, but only backtrack to the first new path and recurse. Then just follow a path until you hit a dead end, backtrack until the first new path, etc. So for example, I had a graph here. Put it here. How about something here? Okay, so there's like a reasonable graph. and say we start here. So in depth first search, we would pick a path. So start here, we would go like here, then we would pick here, and now there's no more edges. We've reached a dead end. So we go back, and then we pick the first new path, right? So now at this node, we could go this way instead. So we would go over here. Now we don't go up this way because we've already been to S. So we go to the first new thing, right? So this is new. Okay, we hit the dead end. We go back and then we go here and then we go here. So that's an example of how depth first search works. And it's different than breadth first writing that in breadth-first you will never go like it's possible in depth-first search to you know go on a really long path way away from the starting vertex at the very start and then come back. In breadth-first search you'll never do that right you always start with things distance one and then distance two etc. So what's the algorithm at a high level? So Again, it takes as input a graph. And so I'm starting at S. And okay, so the first thing you're going to do is mark is explored, and then for each neighbor of S, it's like vertex V with, there's an edge between them, right, between S and V. S, V, edge. All right, so for each neighbor of S, I'm gonna say if V is not marked as explored, recursively invoke the function. look depth first search. On the same graph with V. So this is like the high level. Entire algorithm. And. Um? One thing, let's see, so maybe it's better to just do one more example. just to make sure it's clear how the vertices are being traversed. So this time I'm going to label them clearly. So here we have A, B, C here, D, another edge here, E, F, and then let's put G up here. Okay, so now, what is a possible like EFS traversal order. I say possible, right, because there's no ordering of the neighbors of a vertex s, and we just, you know, we just pick one. So we're gonna say a is the start node. All right, so we started A, and we can go to B, randomly. Then, let's go to C, and then let's go to D, and let's go to F. So we're gonna go A, B, C, D, F. Okay, now we hit a dead end. And so we backtrack to D. The only other path is to A, which we've already explored, so we don't go there. We backtrack to C. There's nothing else to go to. We backtrack to B. Okay, now there's something new. So we backtrack to B. And then we go to E. Okay, again, we've reached a dead end, so we backtrack to B. Nothing new. We backtrack to A, and then we go to G up here. Okay. And now we're going to prove correctness, right? So we're going to say, if there is a path from S to T, And then, all right, depth first search starting at S, explores T. Right, it needs to explore everything that's connected to S. Does anyone have any idea how we would prove this? Okay, so. well we're gonna prove it by contradiction. Right, so suppose there is a path from S to T but depth-first search does not explore T, right? So suppose, suppose not, right? Then, There exists some path, you know, S, then there's some like, you know, intermediate vertices, And then there's T, right? Where, so there's a path in the graph, but T is unexplored. Okay, so I'm not seeing any ideas in the chat. That's fine. Okay, so let's just think a second, right? So there's a path from S to T. T is unexplored. S is explored. By definition, I mean the algorithm starts marking S as explored. Okay, now how are we going to reach a contradiction? So you'll notice, if you look at the algorithm, is that if s is explored, then every neighbor of s will be explored. For each neighbor of s, it was not already marked as explored. We will recursively invoke DFS. What that means is when this thing terminates, we're going to go to the next neighbor. So, what we can say is, let's look at the first unexplored node in the path. Right, so this like, potentially it's like here, say. EI. So everything up to this is explored. And this guy is unexplored. So let VI be the first unexplored vertex in the path from S to T. why does such a vertex have to exist? Well, s is explored and t is unexplored. So either v1 is unexplored, in which case v1 is the first one to be unexplored in the path, or it's explored. Okay, if it's explored, we just look at v2. If that's unexplored, we're done again, right? If Or, they were all explored, in which case, because T is unexplored, then T is the first unexplored vertex on the path. Right? So, you know, such a VI must exist since S is explored and T is not. Right? Okay. Now, also by this assumption, vi minus one is explored, since vi was the first unexplored node, unexplored vertex. Now, also, we know that vi minus 1 vi is an edge in the graph, right, because that's along this path. So we have this edge in the graph where this guy was explored and this one was unexplored. But this is a contradiction, right? because when vi-1 is explored, right, for each neighbor of vi-1, we are going to recursively invoke depth-first search on it. All right, this is a contradiction because when vi minus one is explored, we call, right, we recursively call DFS on all neighbors of vi minus one, which implies we call DFS on vi so vi is explored. Right, and so since we've reached a contradiction, the supposed not assumption was wrong and so it must explore T. Yeah, so then we're done, right? We conclude that T was in fact explored. Okay, let me see. Are there any questions in the chat? No? Okay. So how do we argue that this depth-first search terminates? How do we argue it doesn't run forever? And at some point, all of them are going to be explored. Right. Yeah, exactly. Basically, the only way it could run forever is if we recursively are invoking this depth for a search step, like indefinitely. But, notice it only gets invoked if V is not marked as explored, right? And the second it gets invoked, right, the very first step, once we invoke DFS GV, the very first thing we're gonna do is mark it as explored. So basically, why does it terminate? I guess the simple explanation is the recursive call DFSGV can be called at most once for x, v in the graph. And so the next thing we're going to do is we're going to go over the time complexity of the FS. But before we do that, like we did with breadth-first search, We're going to give another formulation of DFS using stacks. So how does this work? DFS G. So step one is going to be to initialize a stack. Okay, it's going to be empty by default, and then push s onto the stack s. The second step is going to be to initialize explored as an n-sized array with all entries Okay, now what are we going to do? While stack S is not empty, we are going to pop V from the stack. And if V was not already explored, then we're going to set it to be explored. And for each neighbor w of v, we are going to push w onto s. Okay, I guess we can close the while. Okay, so that's the entire algorithm using stacks. And what you'll notice, right, is, so like say we started S, push S onto the Now we enter the while loop. We're going to pop S from the stack. We're going to set it to be explored, and then we're going to push every neighbor of S onto the stack. But then when we iterate the while loop again, we pop a neighbor of S onto the stack, and we push all neighbors of that onto the stack. Because the stack is a last and first out dataset, when we iterate again, we're going to iterate from a neighbor of neighbor of S and so forth. Right. So that's why we're going into depth first manner. So, um, to illustrate this via an example. Um, and I'll say one more, one more thing you might've noticed that if you look at breadth first search, um, with the Q yeah, notice how we step three, right? We set Discover to be true before we enter the while loop. And then inside the while loop down here, right over here, we set Discover to be true right when we push it onto the queue before we pop it off. Because we're going to breadth-first manner, the second we see something, it's been discovered. Whereas in depth-first search, we're not doing that. We're initializing explore, and actually, we're only setting it to be explored once we pop it from the stack. Because we pushed all the neighbors of s onto the stack, the starting vertex. We don't explore them all immediately. We first go down one path, and we only explore the other neighbors once we backtracked to that point. So, for example, let's make a little example here. Say we have some starting vertex s, a, c. Okay, so here's some graph. And let's look at the, now let's look at the how the algorithm runs. So we have our stack and we have the set of explored nodes. Okay, so initially, Explore is like empty, and the stack is just S. Okay, and now we're gonna pop S off the stack, right? That's the first step, so S becomes Explore. And now we're going to push onto the stack all three neighbors of S, which is A, B, and F. Okay, I'm going to say that the bottom of the stack is here, so we're going to pop off the top of the stack is here. So now the next step, we're going to pop A off the stack, right, and add it to the explored list. And now, we push onto the stack the neighbors of A that haven't been explored yet, right? That's what we do here. Let's see, so yeah, so we pop A. We set it explored, and for each neighbor we push it onto the stack. So actually no, we push on everything. So let's see here, so we have... So we would push on, let's say, S and B, and then we still have B and F. Okay, now we pop off S, and since S was already explored, we don't do anything. Right, so we keep explored, and we pop off S. OK, then. We're going to pop off B. And add it to explored. Um? And. The bottom of the stack is the same. We've popped off the off B. And what are all the neighbors of B? There S, A, C, D and E. Okay, now we pop off S, and it was already explored, so we do nothing. Okay, then we pop off A. Again, it was already explored, so we do nothing. Okay, now we pop off C, and C was not already explored, so we add it to the explored list, and now we look. What are all the neighbors of C? Well, it's just B. Right. Right. And then we pop be off be was already. Okay, then we pop D off Sorry, I didn't understand what happened that we added be there This step yes, okay So what were we doing here we had s ABC so we popped to be off the stack and B is already explored right so we pop B off the stack and since B was already explored we do nothing yeah understand but the step before that we didn't have B in the in the stack we just popped the C here this step yeah - Yeah, yeah, so I pop C, I add it here, right? 'Cause it's not been explored. - Yes. - Now, for each neighbor, I'm gonna push it onto the stack. So C's neighbor is B, so that's why. - Oh, okay, gotcha, okay. - Now, okay, I'm realizing now that I've seen two different ways, this is why I was mildly confused a second ago. I've seen two different ways of doing this, which is like you could do a quick check, right? Instead of pushing every neighbor onto S, you could say, I'm only going to push neighbors onto S that are not already explored. That would save you a little bit, right? Then I would say, like, there's no point pushing B onto the stack and then immediately popping it because it's already been explored. But I've seen it written, this algorithm written. This is like the simpler formulation, so let's just stick with this. - So every time we explore something, then we are pushing it back to the thing, pushing all the neighbors of it to the stack, right? - Yeah, yeah, exactly. But then like, you just pop all the neighbors until you get to one that you haven't explored already. - Yeah, makes sense. - Yeah, so continuing onward, we pop D, we add it here, and now all the neighbors of D are, guess just be again okay so now we again we just pop B we just like eliminated okay now we pop e and e actually is new and its neighbor again is B so we just put B back. Okay, now we're gonna pop B. This is the same. Then we pop E. Again, it's the same because these are all explored. Then we pop B. Don't do anything because it's already explored. Okay, and finally we pop F. And onto the stack we'll push s which was the neighbor of f then we pop it and we do nothing again because that's was already explored and so this was our final then the algorithm terminates. Okay now okay we're running a little bit low on time and I just want to make sure I get to the time complexity analysis of depth-first search. So let's just do that now, and that'll answer any questions. So all right. So now let's analyze the runtime of DFS using the stack again. It's here. So the first thing we do is initialize an empty stack and push s. It's just constant time. We initialize explores an n-sized array. So of n time. Okay, and now here, well, S is not empty, right? That's like a, we'll have to think about that one. But then, pop the from the stack, just takes constant time. Checking this takes constant time. Setting this takes constant time. And pushing sub takes constant time. But for each neighbor w of v, This again is O of degree, V time. Okay, now, before, how did we argue it right with breadth-first search? Well, we said something like the while loop is gonna be executed at most once per node because we never push the same node onto the stack twice. Unfortunately, that's clearly false in this case, right? We push b so many times on this stack. So we can't use that analysis. But what we can note is that this if statement, is executed at most once per vertex. Right, because it's only executed when explore was set to false, and the second it's explored, we set it to true, so we're never going to run this twice for the same vertex. And each time we run this, it takes O of degree of V time plus some constants. So, let's just write this here more formally. So, the inner if statement is executed at most once per v and takes o of degree v plus o of one time. You have to keep this o of one time around because what if the degree of the of v was zero? So you still are taking some constant time just to like, do these explored operations. So basically, again, you know, if we sum over, like, at worst, we executed once per every v, and so the total time here, total time of the if statement is bounded by sum over all the vertices in the graph of degree of v. Okay, I'm just gonna remove the big O around this because it actually takes degree of v time. So, I don't know. It's easier to just see it this way, right? So it takes sum over this plus O of one, right? These are all in the summation, and as we saw before, this is 2m plus then o of n time. Okay, and then the time before the while loop, right, the time here, these two steps before the while loop, that's o of n time. So, the last thing is time, or rather like, let's say number of iterations of the while loop, right? number of executions of the while loop. Because what have we counted so far? I've counted steps one and two, and I've counted everything inside the while loop, inside the if. What I've not counted is all those times where we just, we popped something off the stack and we were like, "Oh, it was already explored, so we discarded it." And that happened kind of a lot, if you noticed. However, we can actually bound the maximum number of times we push something onto the stack. And the reason is, when we push stuff onto the stack, we only push stuff onto the stack right here. and it's for each neighbor w of v, right? So, this if statement is executed at most once per v, and when it's executed, we push at most degree of v things onto the stack. So, number of executions of the while loop can be bounded by maximum number of pushes onto the stack, and this, in turn, is bounded by sum over v and v of the degree of v. Right. This is the iterations of the if statement. And this is the number of pushes onto the stack in that iteration of the f statement. And again, this was 2m, which is O(m). So when we add everything up, we get a total time of, you know, O(m) plus n, some more O(n), some more O(m)s, and all of it together is O of M plus N, which is also, if you recall, the exact same time complexity as breadth-first search. We seem to have just run out of time, so this was good timing. Are there any more questions? For cases of small m and n, would breadth-first search or depth-first search be better? Yeah, this is a good question. It really depends, I think, on the structure of the graph. So, you can have graphs that are... So there's two properties people call, like, the depth of the graph and the width of the graph, right? So breadth-first search is good for graphs with large width, meaning things kind of spread out nicely. So here, BFS versus DFS. So if you have a graph that kind of looks like this, And then these guys maybe are like, show this. Okay, BFS is pretty good here. All right, the graph has pretty good width. You're gonna start here and you're gonna go like here, here, here, right? You're like expanding outwards nicely. So BFS is pretty good. DFS, DFS is better suited for like a graph this. You kind of have these long paths and it's not very wide. There's not a lot of branching happening. Now, it also can depend if you know some information. Sometimes you know that the node you're searching for is not near the starting node. And in that case, doing depth-first search can be useful. You just go down a path. I mean, you might get lucky and get it early. You might not. But it really depends on the application. That's why. But in general, breadth-first search, I mean, so one thing you definitely want to know, definitely remember this, because this is what everyone always asks, is breadth-first search is is queues, depth-first search is stacks. And I mean, a nice property of breadth-first search is it actually finds the shortest path to a node in the search. The layer it's in tells you the shortest path from s, whereas that's not true for depth-first search, because-- Like in our example up here, the shortest path from S to B is just 1. But we actually went through it by going S to A to B, which is not the shortest path. And I guess one final comment is that the time complexity of DFS and BFS is similar, but this DFS analysis is more involved because we have to also bound the number of executions of the while loop. We can't simply say it's only executed once per vertex. Fortunately, we're able to do that by bounding the number of pushes on the stack. OK, so if there aren't any more questions, that'll be it for today's lecture and then I'll see you on Wednesday. Thank you. Yeah, thanks. Actually I have a question. Yeah, sure. So for the time complexity analysis for DFS, it looks, as you mentioned, like it looks like we have more like Ms and Ns. So does that mean that DFS has like more constant factors for MMM? Um, unclear because. So sometimes, let's see so. OK, the reason it's unclear is because it just depends on the implementation of how like how fast can you implement the queue and the stack, but it does, like, I think you would be correct if we're gonna assume that, so like discover checking things and discovered versus explored, that would be the same. And assuming the queue operations take the same amount of time, then yes, because in depth-first search there's all of this extra pushing and popping from the stack. However, there's a difference in that. In depth research, we just push things on the stack, we don't check if it's already been explored when we push onto the stack. We check that later. Whereas in breadth-first search, we don't push things onto queue until we've already checked if it's been discovered. But I think in general, yeah, what you're saying is correct, that the depth-first search is taking more operations. In fact, we kind of noticed this, right? Like when I wrote out the algorithm, it's like, look how many times we were pushing things and popping them from the stack. But I think what I could have done is I could have just put right up here, right? An if statement to check if it was explored or not before I push it on the stack. And I think if I did that, it would be very similar to breadth-first search in terms of operations. All right, I understand now. Thank you.