All right, awesome. So first of all, I just wanted to ask if anyone had any questions about the class or the content. At this point, the waitlist has decreased a lot. So if you're still on the waitlist, there's a decent chance you'll get in. I've been talking with the enrollment office about trying to let those students in, but no guarantees at this point. I know there was a little bit of an issue with a couple students getting dropped from course involuntarily. We're handling that right now. So, uh, yeah. But first of all, I guess, are there any questions about the class? Um, yeah. So for the, uh, the Piazza link, I don't like the dot UCLA email. I only have like my own personal email, like my other school email. Is there any other way to still join that, uh, discussion thing? Uh, yeah, there should be. I'll, I'll make a separate link for that. Or if you send me an email, I can manually. Okay, perfect. Thank you. Yeah, question. Oh, and homework one will be released soon and will be due Saturday of week two. Normally this would be due on Friday, but Friday is a holiday, so I'm extending it by day. Okay, awesome. So at this point I will share my screen for the lecture. All right, so this is lecture two, and we're going to pick off where we left off with the Gale-Shapley algorithm today, and then afterward we'll talk a bit about how we can analyze the efficiency of algorithms, including this one. So when it comes time for the homework, you'll need to do a couple things. First, you'll need - so if we ask for an algorithms problem, then you'll need to show an algorithm. So this can be kind of like a high-level pseudocode of it, and then you'll need to prove its correctness, and then you'll need to analyze its efficiency. So those are generally the things you'll have to do in this class. Whenever we ask you to write an algorithm, we also want you to prove its efficiency. And I'll talk a little bit more about what level breaker is required for that a little bit. Okay, so just to review, what was the problem? So we imagine that we have n hospitals and n students. So this is from last lecture. And hospitals each want to take one student. Each student wants to be assigned to a hospital. and the hospitals have a preference list of which students they like best, and the students also have a preference list of which hospital they like best. Okay, and we define a matching to be ways to pair up students and hospitals, where every hospital appears in at most one pair, and every student appears in at most one pair, but it's possible for students and hospitals to be unmatched. Whereas in a perfect matching, which is what we'll aim for, every student and hospitals match exactly once. So in this case, we require that the number of hospitals is equal to the number of students so that every hospital can have exactly one student and every student can have exactly one hospital. Okay, now if we only just care about perfect matching, then we're not taking into account the preferences of the hospitals and the students. Therefore, what we're going to do is define an instability, which is a situation in which a to switch pairings. So an instability occurs if a hospital is paired with a student, another hospital H' is paired with a different student S', but H actually prefers S' over their current match, and S' prefers H over their current match, which means there's an incentive for H and S to say, "Forget the matchings you assigned me, I'm going to create a new matching with someone else." So again, this has to be both ways. If S' wants to be with H, but likes their current match better, H has no incentive to switch. Similarly, if H wants to be with S', but S' likes their current match better, then S' won't want to switch. So our goal for this problem is to be able to find a stable matching, which is simply a way to match up every hospital with every student, such that this situation doesn't occur. So nobody has an incentive, at least by talking to one other person, to want to switch matches. Okay. All right. So anybody unclear on what the problem is asking? All right. Awesome. So then I defined this Gale Shapely algorithm named after Gale Shapely. And I didn't explain at all why this works. That's what we'll be doing today. But this is how the algorithm works. So it takes its inputs, these preference lists for the hospitals and students. And it initially says nobody's matched together. That's this is the empty set. So we set the this will the matching and will be the kind of matching we output. Eventually, we just initialize it to no matches. So start. And then what we'll do is we'll go through the hospitals. and as long as the hospital doesn't have a match, then we're going to have them make an offer to the highest student on the list that they have not yet made an offer to. So the very first hospital will make an offer to the first student on their list and they'll keep going down the line and then if the first hospital, the hospital is rejected by the first student on their list, then the next time they make an offer it'll be the second student on their list and so on and so forth. and we'll continue this process until, you know, either every hospital is matched or some hospitals, you know, aren't matched, but they've made an offer to every single student and therefore they just give up at that point. Okay, and so what happens when a hospital makes an offer to a student? Well, if the student is not matched yet, so if the student is unmatched, then the student will say, "For now, I guess I will match with you." So if say UCLA made an offer to Alice, and Alice didn't have any other offers at the moment, then Alice will say, "Sure, for now, I will agree to be matched with you." So that's what this means. It means we're going to match Hospital H with Student S. Otherwise, if the student is already matched, then the student will compare their current match to their new proposal and decide which one they and Cedars-Sinai came around and said, hey, do you want to be matched with me? Then if Alice likes UCLA better, Alice will just reject Cedars-Sinai. But if Alice likes Cedars-Sinai better, then Alice will go to UCLA and say, hey, UCLA, I no longer want to be matched with you. That's what this means. It means we'll remove the old match from the matching and then say, I will now be matched with Cedars-Sinai. So that's what that means. We'll add the new match to the matching set. So again, just to summarize what's happening, hospitals are making offers in order of preference while they're unmatched. And if a student is given an offer, then they will match if they don't have any offers. And if they already have an offer, they'll either reject their old match and go with the new one, or they'll reject the new offer, whichever one they like best. OK. And we did an example of what this would look like last time. Oh, yeah, so someone asked a question, how can a hospital make an offer to every student but still be unmatched? So this is something we'll talk about in a little bit. In fact, it will turn out that maybe the situation can't occur, but at least in the wild loop condition, it's not necessarily clear yet whether or not the situation could occur. So we haven't analyzed it. currently we've just explained what the algorithm is. And down the line, what you guys will be doing is we'll be coming up with these algorithms yourself. Any questions on what the algorithm does before we go into analysis? So for this problem, these proofs are actually a little bit more complicated than some you might see. But when we're trying to do proofs, there's not necessarily one specific method. There's a couple of different ways you can do proof techniques. But what you want to do is you just want to be able to convince someone. So you want to make sure that all the logic you say is consistent. And you want to be convincing enough that someone will be like, yeah, I believe this works. I believe that everything you said here is valid. So let's talk a little bit about algorithm analysis. So the first thing we care about is, is the algorithm correct? And so important things about this is, does it output the answer you wanted? In this case, we're asking if the output is stable matching or if there is no stable matching, if it tells you that there is no stable matching. And another thing for this class, we always want our algorithms to terminate. So if your algorithm does not terminate, then it's not outputting any answer at all, which you could also think as a wrong behavior. Now, there could be situations where you're okay with your algorithm not terminating, but generally speaking, you do want your algorithm to always at least say yes or no, or a timeout is generally not okay because you just don't know, right? Like, what does it mean if the algorithm keeps running? Do you know what the algorithm finishes? So it is important for this class, again, that all your algorithms always terminate. You never have live while loops that run forever. OK. The second thing we'll do is talk about how efficient is the algorithm. And this we'll talk about in the latter part of the class. OK. Now, keep in mind that if you prove that your algorithm runs in at most some time, then that implies that it terminates. because otherwise you can't have an upper bound on this runtime if it doesn't terminate. So if you can prove that your algorithm, say, runs in some number of steps always at most, then that also implies that it terminates. So what does it mean for this algorithm to be correct? Well, remember our goal was to say, given a preference list of students, find a stable matching. So we want to say that our algorithm always outputs a stable matching. Now, this is a little bit hard to do off the bat. You might look at this and think it's very complicated. You know, what's going on here? So we're going to just do this, break it down into a little bit of easier steps, and then we'll kind of carefully build up to the stable matching. OK. So I'm going to first start with a couple of observations about how the algorithm works. So how this I'm calling observations, since you can kind of see them by looking at the algorithm. They don't really require additional proof to see. So observation one is that once a student has made an offer, it's made their first offer. They become matched and never become unmatched. And then additionally, the sequence of hospitals they are matched to only gets better and better. Only gets better and better in terms of the students' preferences. OK, let me just write this down, and then I'll explain what this means. Okay, so the first part of this is I said that once a student is made an offer, they become matched and never become unmatched. So why is this true? Well, we know that when a student is made their first offer, if we look at the algorithm, then they always accept an offer if they don't have a match. So that was up here. If they're unmatched, they always accept the offer. And then once they become matched, then we know that the only thing that happens is if they get a better offer, they might switch to the better offer. But at no point do they just reject their current offer for no reason. So this is just when you look at the algorithm, what happens is a student, if they're an unmatched, they will accept any offer they made. And then at that point, the only thing they'll do is upgrade to offers they like better, which is what happens here. So they'll just stick with their current match until the algorithm ends, unless they get a better offer, in which case they'll go with the better offer. Okay. Any questions on this first observation? Okay. And our second observation will be about the hospitals, is observation one. Observation two is that while students basically only upgrade to better and better matches, hospitals only downgrade to worse and worse matches. So the sequence of students to whom an hospital gets matched, Oops. Only gets worse and worse. All right. And why is this true? Well, if we look at the algorithm, what we see is that the hospitals are making offers in order of their first preference, then the second preference, and third preference, and so on. And they only really make offers to the next student down the line if the previous student rejected them. So because hospitals are making order offers in preference order, then you know, if no one ever rejects them, then they're matched to their favorite person, and then they just kind of have to go down the line as they get rejected. Okay. All right. So yeah, we can see it's interesting enough that the students, you know, they're as algorithm goes on, they might get and we won't really have time to cover that in this class. It's kind of in the expert notes I added, but you can actually prove things about, you know, students will actually get very non-optimal matches and hospitals will get fairly optimal matches in some sense of the word. Okay. All right. So now I've established some facts about the algorithm, and again, this is the first thing you want to do when you see a new algorithm. You kind of want to look at it and see if you can notice any behavior happening in the algorithm. And now we want to say there's a stable matching. But a stable matching is a more complex definition. So we're just going to start by first saying there's a matching output. Then we'll upgrade to a perfect matching. And then we'll upgrade to a stable matching. And this will make the proof a little bit easier, because we're just going one step at a time. So let's do our first claim, which is that the Gale-Shapley algorithm always outputs a matching. So recall what is a matching. A matching just says that it's a set of pairs such that no hospital is matched to more than one student. So a hospital can be matched with at most one student. And no student is matched to more than one hospital. So a student can be matched with at most one hospital. And students in hospitals are allowed unmatched. So that's what the matching means. If you recall the definition up here again, every hospital and student is in at most one pair, meaning one or zero pairs. Okay, so looking at the algorithm, does anyone have an idea why it should be the case that this algorithm always outputs a matching? It doesn't have to be perfect, it's not be stable, just some sort of match. Yeah, Dayong? Would it be because the termination while loop of our algorithm requires that every hospital be matched to exactly one student or even though it's not a perfect matching the while loop ensures that every hospital is matched to a student? Okay, so yeah, you have some ideas here. you're looking at this while loop condition, and you're saying kind of like, yeah, we're trying to get hospitals matched because when they're unmatched, they allow them to make offers. So this actually will tie in a little bit more to when we talk about perfect matchings, but certainly this is important here is that, in fact, they're only making offers when they are unmatched. So I guess when you're kind of first looking at these things, at these proofs, When I first go back to a definition, right, the definition says of a matching, says that every hospital is matched to at most one student and every student is matched to at most one hospital. So you wanna separately kind of talk about both those instances. Okay, but yeah, yeah, good observation. And then Nemo said in the chat, whenever we make a new match, it only occurs if there is no previous match or if it replaces the old one. So yeah, so that's exactly right here with the student side is that we notice that with the students, a student basically either is unmatched when they make a new match, or they have to give up their old match to get the new match. So putting together what Daniel and Nimo said, we can get our proof together. OK, so let me just break down a little bit more. So again, how do I approve the statement? I just go back to the definition matching. And what does the definition matching say? It says, first, every hospital is matched to at most one student. So let me write this down. So we say hospitals only make offers when they are unmatched. OK, so thus a hospital can only be matched to at most one student. So if a hospital already was matched to a student, they would not be making offers to more students. And therefore, the first condition of the matching is satisfied, and that a hospital is only matched to at most one student. Now, the second premise, which again, says students are matched at most one hospital is exactly what Nemo said here. So students only accept offers if they are unmatched or if they give up their current match. Thus, a student can only be matched to at most one hospital. Most one hospital. OK. So yeah, so basically, all this proof is doing is kind of like formalizing and organizing what was being said by you guys. So you guys have this intuition for it. And what you want to do is kind of just really drill down into what is the question asking, right? What is the matching? Well, matching says hospital can be matched to a most-want student. Student can be matched to a most-want hospital. And then let's just reason about a little bit, right? It can just be like a sentence or two explaining why this is true. So that's kind of what these proofs will look like. Okay. Any questions on this proof here? Don't you need to prove that the algorithm terminates or did we already do that? Oh yes, good point. Yes, so I guess what I've only proved so far is that the algorithm outputs a matching if it terminates. And I have not yet proved that the algorithm always terminates, so it's possible that the algorithm might not terminate, in which case it would output nothing. So that's a good point. Can we prove that the number of matches only increases never goes down, so at the end it will terminate? Okay, yeah, so that's a good idea. So you're saying, what if we just say that in every step, the number of matches always increases. So this is kind of like would be a progress type thing to say that at every iteration, you know, something will improve. On this case, it's a little bit less straightforward, because the number of matches is always non decreasing. So it's possible for it to increase, but it's also possible for it to stay the same. right? If S rejects the offer, you remove one and add a new one. So it's theoretically possible without, you know, doing more analysis that basically people just keep swapping matches over and over again and no new matches are added. But that's a good idea and that's kind of like a type of proof you can do on other algorithms where you say, you know, every iteration something gets done towards the goal and eventually will reach the goal. Yeah. But yeah, I guess this is this algorithm always terminate? And if so, why? Okay, so I see someone in the chat said yes. I think the key is to say that the while loop must terminate because the cardinality of the the student list is the same. So there will never be a time where you cannot match a hospital to some student, right? So by the end of your, by the end of like going through like, like just, just for one step going through one hospital, you will have it matched with a student. So as long as you keep matching hospitals, by the end, I'm not explaining this very well, I'm sorry. But essentially end you know that every hospital will have a match and because the cardinality of the two is equal you actually know it's also perfect matching. Okay yeah so you have some great ideas here you're talking about the while loop condition and is it possible for hospital and students to be unmatched and kind of your intuition that you're saying is that well there's the same number of hospitals and students so if some hospital is unmatched then probably some students unmatched they should be able to be paired up down the line. So, yeah, this is definitely a way we can go. I'm just going to focus in on the while loop for now, just to break this down into smaller steps. But certainly, if you wanted to do this all at once, you could do this in a longer proof where you prove both of the terminates and there's also a perfect matching. And then someone also talked about the chat about, again, the while loop, what's happening here. So yeah, both of you mentioned the while loop. We want to say it terminates. And why does it terminate? Well, if you look here, there's only a finite number of offers that can be made. So a hospital can make an offer to students that they have not made offers to, but they're not allowed to remake offers to students they've already made offers to. So each hospital can make at most n offers, and then they can no longer make offers in this while loop, and there's also only n hospitals, so the maximum number of iterations here is n squared, which means eventually, if all else fails, we'll get down to step three. So let me write that out a little bit. So, the claim, the Gale-Shapley algorithm always terminates. terminates. What's the proof of this? Well, I'll say always terminates in at most n squared iterations of the while loop. And the proof of this is as follows. So we say in each iteration, A hospital makes an offer to a student they have not yet made an offer to. Thus, each hospital can make at most n offers, one to each student, and there are n total hospitals, so there can be n squared total of such offers. So thus, each hospital can make at most n offers. We'll say one per student. Since there are n hospitals, there can be at most n squared total offers for iterations. So that's the proof. So let me recap what this is saying. It just says that every iteration, some hospital makes an offer to some student. Each hospital is not allowed to repeat offers, so every hospital can make at most n total offers, and there's n total hospitals, n times n is n squared, which is the maximum number of iterations that could occur. And since the number of iterations is bounded by something, that means that eventually the while loop will end and our algorithm terminates. Okay. Any questions on this? Okay, and so yeah, I'm having a lot of proofs for here. Again, some of these proofs are a little bit more complicated, but the idea is kind of to get you used to, you know, having this intuition and seeing how it looks when you formalize it on a piece of paper. Yeah, so someone said to prove terminate, we just need to prove there are finite iterations. Yes, in this case, if we look at the algorithm, the only reason it wouldn't terminate potentially is if this while loop ran forever. And so to prove that it terminates, you have to prove that it won't run forever. Another way to say it won't run forever is that the number of times it runs is less than infinity or finite. So in this case, that is true. Generally, the things you want to look out for is the same things you would look out for when you're writing code. Does my for loop run forever? Does my while loop run forever? Kind of statements like these things don't tend to run forever. Usually, it's loops that might be an issue. And many of your algorithms will be fairly straightforward to say they terminate. If you just have two nested for loops and they each run for iterations, then there's no reason that it should go on forever. And in those cases, you can just say, the algorithm clearly terminates. So we've now proved that the algorithm terminates and that it outputs a matching. And again, you could do these proofs together in one larger thing. I'm just doing it a little bit more step by step to make it more clear what's happening. So now I'm going to do one additional upgrade on matching. I'm going to say that now it's going to be a perfect matching. And then once we get the perfect matching, then we'll get to stability. Okay, so it's gonna be my next claim is that the Gale-Shapley algorithm always outputs So before we said that every hospital student was involved in at most one match, and now we want to say that every hospital student is involved in exactly one match. So just to start us off, well actually, yeah, I'll, I guess I'll first ask, We heard a little bit about this before, but when you're seeing this claim, you want to go back to the definition of perfect matching and say, what's different? In this case, it's the exactly one condition. So are there any additional intuition people have about why the matching should be perfect? Or why or why not? I'll go back to that one. Is it possible for there to be a hospital student at the end who are unmatched? So if I can have another go at this. I think the, okay, so you start with saying that every hospital must get matched to like at least one student. And you can say that by, because you know that the preference list contains every student. So eventually you will come across a student that does not yet have a hospital. And the reason why we know there will eventually be a student that doesn't have a hospital is because each hospital can at maximum have one student, according to our if statements. So whatever hospital number you are is how many students are already matched. You know there's always going to be at least one student left. Because there's at least one student left, you know you'll get matched with one student from your preference list. And then if you go through every hospital with each student, each time a hospital gets exactly one student because you have two lists. You have n students and n hospitals. You're going to have exactly one match for every hospital and then it's a perfect match. You know that they're distinct, that's also key. Is that no student can get matched to two hospitals according to our conditions. >> Yeah, that's great. I'm just going to formalize a little bit what you said, but basically everything you said was correct. So let me kind of re-sort of write what you said. So you said, all right, suppose we have a bunch of hospitals and students. This is hospitals, this is students. And a whole bunch of them have been matched up. I don't know, something like that, let's say. And what you're saying is that-- let's say this guy is unmatched. Then, well, if you look at the students, the maximum number of students that can be matched is equal to the number of hospitals. We said that since each hospital can have at most one match, which we previously proved, at most one match, Then the number of matched students is at most the number of matched hospitals. And therefore, what that means is that with number of students equal number of hospitals, number of hospitals, student is also unmatched. A student is also unmatched. OK, so yeah, the first part, what was said, was, again, if there is an unmatched hospital, then there must also be an unmatched student. And why is that the case? Well, we previously proved that every hospital can have at most one match. So therefore, the number of currently matched students must be at most the number of hospitals. And so that means there must also be an unmatched student. OK. Someone said, is this number? I'm not sure what they're asking. OK. Yeah, I'm not sure what that question was asking. So yeah. So now we say, OK, if this-- so yeah, I guess, first of all, is there a question about this first part of intuition is that if the hospital is unmatched, there should also be an unmatched student. Okay, and then the second part is that can this occur? Can we end up with an unmatched hospital and unmatched student? Well, we shouldn't because the only way for this hospital, you know, so if we look at the algorithm, right, how does a hospital remain unmatched and we get to this step? Well, that only happens if they've made an offer to every single student on their list and they've been rejected by every single one. So at the end of the algorithm, this hospital can only be a match if they've made an offer to every student, including this guy here. But, you know, if they make an offer to the student, the student should have accepted. There's no reason for the student to be a match. So that's kind of how the idea will go. So let me just write down a little the unmatched hospital, we'll call this, we'll call him H, and the unmatched student, student S. You can say that H is only unmatched at the end, the end, if they made an offer to every student. And then we can say, if so, S should have been matched with either H or someone else with either H or another hospital. Okay, so again, what is happening here, right? How is S unmatched? Well, S can only be unmatched if they've never been made an offer by anybody. And so, the H is supposedly made an offer to every single student, including S. So we kind of have a contradiction here. Okay, so again, this is just the intuition, and then I'm going to kind of turn this into a proof. But what we kind of see is like, if this situation occurs, which is a bad situation, then something must have gone wrong. And this is an example of what's called a proof by contradiction. So in a proof by contradiction, we say, suppose that the statement is false, then we're going to imply this will imply that something goes wrong. And if something goes wrong, then there must be an issue with our proof. And as long as the issue is not our logic, then the issue must have been our initial statement, which was that the statement was false. So let me just write what is a proof by contradiction. So you want to say, suppose you want to prove some statement x is true. Then in the proof by contradiction, you'll say, suppose x is false. And then assuming this, you're going to derive a contradiction, which is just something that should not or cannot occur. Something that cannot occur. And what does this mean? This means that something went wrong with your proof. If you're proving false things, something must be wrong. And if your logic is correct, the only thing that can be wrong is this initial statement that x is false. And then if x is not false, then x must be true. So we'll say, this means something went wrong with your proof. And if your logic is sound, this means the initial statement, initial assumption of x is false cannot be correct. So x is true. x must be true. So that's what a proof of contradiction is. Again, you just say, suppose the opposite. Suppose the opposite. Then bad stuff happens. But bad stuff can't happen, so the opposite can't be true, and therefore, the original statement must be true. And this often occurs when you have a counterexample. Like let's say I said, every number is prime. And you say, well, let's look at number 4. 4 is 2 times 2. But you said every number-- if every number-- sorry. If I wanted to prove that-- so if you want to do a counterexample, well, your statement that every number is prime is false because I created something that's not prime. And therefore, every number is prime cannot be true. And that could be a way you can prove that there exists a number which is not prime. Any questions on what a proof by contradiction is before we actually prove the statement? Yeah, so, you know, I've seen basic proofs of contradictions and plenty of other classes, and they seem to rely upon the fact that you only really have like two premises. So if you have two premises that are relevant, and then you prove they contradict each other, well then one of them must, or like, you know, the existence of one means the, you know, existence or like the lack of existence of another. But I'm wondering if, you know, let's say we have an algorithm which in which we have like a lot of premises and the proof is very convoluted or whatever, I find that it might happen that it would be easy to come to a contradiction and then maybe not be able to show that, to show which one of your premises must have been wrong, and I'm wondering how you recommend avoiding that kind of situation. Okay, so I think what you're trying to ask is more a question of like, how do we decide what type of proof to use? When do we use a proof by contradiction? Which premises do we involved in the proof by contradiction. I'm trying to summarize what you're saying. So, yeah, so here I'm using a proof by contradiction because I think it's the easiest way to prove the statement, but generally speaking, when you look at a statement, you can prove it usually many different ways. So, when I look at the statement, right, so one thing I could do is try to say, just prove, right, that the properties of the thing being output is always perfect. And that's in fact kind of what we did when we did the matching. We just say look at what happens. Here's what always happens. Now for this case I actually thought that it was like okay. In fact it's a little bit easier for me to show that you know the case where someone's unmatched just cannot occur. So often you can try to think of your statement and you can try to think of the opposite of the statement and think, what can I think about that? If you're looking at the statement, and you're like, I see these properties just emerging from the algorithm, you can do a direct proof. If you're thinking about the opposite of your statement, that can give you another tactic to approach the program and say, oh, wait, hold on. What if this did occur? That doesn't seem right. So if that's the kind of tactic you're using, then a proof by contradiction will be what you want. But most of the time when you're coming with these proofs, you're doing them actually hand in hand with the algorithm. So in this case, I just gave you the algorithm, and now you have to come with this proof. But in reality, kind of future, down and further in the class, what you'll do is you'll have some insight. You'll say, here's what I think. And then you'll try to prove it. And then something will go wrong with the proof, or you'll say, oh, it could be the case that someone's unmatched. That's bad. Let me go back to the algorithm and fix it. and then you use what you fix to inform the proof on the next attempt. So generally speaking, these will be kind of a hand-in-hand thing, and what type of proof you do, right, inductive, proof by contradiction, will just be a matter of your choice and preference of how to prove it. But in general, there are multiple ways to prove things. So I'm not sure if that really answered the question there, but a lot of this will be just kind of playing with the algorithm, seeing what kind of stuff you can reason about it, and then trying to figure out how to formalize that insight. And again, this is a new sort of concept for this class, so I expect proofwriting will be difficult for a lot of you. But that's OK. You'll get lots of practice in this class for the future. So yeah, so I'm going to now prove this. Let's copy this down. Okay, so we're just going to go off of the intuition we had before. And all I'm going to do is just kind of write down what we said. So we have this intuition here. We said, well, a hospital is only a match. If a hospital is a match, a student must also be a match. But a hospital can only be a match if they get an offer to every student. And a student can only be a match if no one's ever made them an offer. and therefore this situation cannot occur, which means our original premise, which was that some hospital was unmatched, is false. Okay. So, okay. So let's say suppose for sake of contradiction. So what does this mean for sake of contradiction? That's just me, oh, by the way, I'm doing a proof by contradiction, And I'm going to suppose that the opposite of what I'm trying to prove is false. And that's kind of how you lead into a proof by contradiction. That Gale-Shapley does not output a perfect match. or outputs, let's just say, Gale-Shapley outputs M, such that M is not a perfect matching. So M is just whatever the Gale-Shapley algorithm output. OK. Then we said by the previous claim, m must be a matching. So previously we claimed that the Gale-Shea play algorithm always outputs a matching and now we're trying to prove it's perfect but the previous claim still holds that whatever the Gale-Shea output must be at least a matching which means everyone's involved in at most one match. OK. So then we can say, since there are an equal number-- so actually, let me-- So this means there is at least one hospital or student that is unmatched. So this is just by it-- let me just reorder these, actually. So by the previous clans matching, and so in order for it to be a matching but not a perfect matching, then there needs to be some hospital or student that is unmatched. And this is just by the definition of matchings and perfect matches. And then we can say, but since the number of students equals the number of hospitals, and each student's hospital is in at most one match, since we're in a matching. There must be both an unmatched student, student S, and an unmatched hospital H. Unmatched hospital H. So this was really just what I wrote, was the intuition that equal number of students, hospitals, everyone can be at most one match by our previous claim, right, that it's matching. Therefore, there must be a student and a hospital who is unmatched. So now we want to just go to the second part, which is that we can say that by the algorithm, age can only be unmatched at the end, oops. unmatched at the end if H has made an offer to every student, an offer to every student. And by our observation, which is also by the algorithm, S can only be unmatched if they've never been in an offer. So by observation one, which again, what was observation one, it said that a student, once they become matched, once they are made an offer, always stays matched because they only trade offers at that point. So by observation one, S can only be unmatched if they have never been made an offer. But this is a contradiction. A contradiction, since it means H should have made an offer to S, should have made an offer to S, and S should also, S should have received no offers. Received no offers. Sorry if my handwriting is a little messy. I can repeat any of this if you can't read it. Okay, so yeah, let me just summarize what I said here. The first part says there should be a student and a hospital who are both unmatched because every student in hospital is involved at most will match by our previous claim, and there's the same number of students as hospitals. And our second part of algorithm says how does this occur? Well, on the hospital side, we know hospitals are only unmatched at the end if they've been rejected by basically every student, so they must have been offered to every student and eventually been rejected. And our other observation said on the student side, students are only unmatched if no one ever makes an offer because they always accept if they're unmatched. But this is a contradiction because how can a hospital make an offer to S and S also say I've never received any offers. And since we have a contradiction, that means something must have gone wrong with the proof. And if it's not my logic here, then it must have been the original statement, which was that M is not a perfect match. Therefore, M must be a perfect match. Okay, this is kind of a lot to take in. Are there any questions on this? And again, this is just following the intuition we just wrote above. Yeah, I have a question about the perfect matching. So if we know that that Algor is giving us matching, and we know that the number of H and S are the same, doesn't it already like prove that it should be perfect matching? 'Cause when we have matching and the number of H and S are the same, it only can be perfect matching. - Ah, good question. Yeah, so the question was, is it possible if we know that the number of students is the same as the number of hospitals, and it's a matching, does that imply it's a perfect matching? And not quite. So let's say we have three hospitals and three students. Then the following, where there are no matches at all, is a matching, but it's not a perfect matching. Or if we have one match here, this is also a matching, but not a perfect matching. So in a matching, the number of matches does not have to equal the number of students or hospitals. The number of actual matches can be zero. So just because it's a matching does not imply that it's a perfect matching, if that makes sense. Oh, I thought matching is like there is at least at most one pair. Oh, OK. Oh, yeah. At most one means zero or one. So it's possible for everyone to be involved in zero matches, which satisfies the definition of matching. OK. OK, my bad. But these are like subtle definitional points, so it's good to think about these things. But yeah, so yeah, again, another thing I want to really drive home is that when you come to these proofs, a lot of the times the first thing you'll do is you'll go back to the definition of the thing you're trying to prove and you'll say, how exactly do I just say, right, you just put the definition part, you say, first, I show this part, this part and this part of the definition. Now they've all been satisfied. So when you see these new problems, and you're kind of like, how do I prove this? Again, first go back to the definition and really look at what is the definition specifically and how do I prove each of those parts of it. Okay, so we're going to do one more proof which will complete the Gale-Shapley thing and then we'll take a break and then after that we'll talk about order notation and analyzing efficiency of algorithms. Okay, so here's my last claim. You can also call these, oh yeah, so if you see in this class, theorems are and lemmas are things I might use. A theorem is generally kind of the proof that people care about. Theorems and lemmas are both like essentially claims that you're approving. Generally the word theorem is used for the more important ones and lemmas are used for things used to support the general theorem. class it doesn't really matter whether you say theorem or lemma or claim, just that you prove statements which are not obvious. I guess, okay, so maybe obvious is the wrong word. So what is the standard when you need to prove something is that if you're talking to a friend in this class and you said this is true and they said yeah yeah I totally get that they don't even have to think about it then that's fine you don't have to prove it but if I say yeah it always outputs a perfect matching, you kind of look and you're like, "Yeah, we see that." That's when you need to have a proof. So you could even do this with a friend and say, "Hey, let me prove this to you. I want you to not do very much thinking at all. Are you convinced by what I said?" And that's kind of good for the standard class. Okay, so let me do the last proof, which is the Gale-Staple-Chapley algorithm. always outputs a stable matching. OK, so we know it outputs a perfect matching, which means every student in every hospital must be paired with exactly one other. And now we want to say that no instabilities occur. So let's go back. So first, we want to go back and say, what is a stable matching? So let's go back. Okay, so a stable matching is stable if there are no instabilities. So what is an instability? An instability is the case where pairs are matched, but there is one of each in the pair that would like to swap. That's an instability because they have incentive to break the agreement of the match and not do that and instead run off with each other. Okay, so here we're also going to do a proof by contradiction, which is we're gonna say, suppose that this situation occurred, and then say that this cannot actually happen. Now, again, you could do this directly. I chose a proof by contradiction, but I'm gonna, for the proof by contradiction, I'll say, let's suppose it wasn't stable. Then there needs to be an instability. And if there's an instability, how could this have arisen? And why can't it happen? OK, so let me just copy this down. And we'll kind of talk about the intuition of the proof here. OK, so for intuition, I'll say I'll do a proof by contradiction. And we'll suppose there's an instability. And then this ability would look something like this, right? There's a hospital and a student pair HS and H prime and S prime, these guys are matched, but H and S prime prefer each other over their current match. Okay. And in this case, we're gonna break it up into, so, okay, so yeah, so we're gonna ask, Okay, if H really likes S prime more than S, then H really should have made an offer to S prime first. Right? So we'll make that a case one. We'll say that H made an offer to S prime at some point. And why would we think maybe H would make an offer to S prime? because H supposedly like S prime a lot, and so you would expect, you know, H to be like, "Yeah, hey, S prime, do you want to be my partner?" Okay, now we know that the only reason H did not end up with S prime, right? So, yeah, so actually maybe I'll turn this, yeah, so because H did not making H is not with S prime. Since H is not with S prime, now S prime must have rejected H at some point. Rejected H. So we can imagine a case right here's H and and they've made an offer to S'. So H made an offer to S'. And at some point, S' said, "Absolutely not. I want to go with somebody else." We'll call H double prime. So at some point, S' rejects H in favor of someone else. But recall that S' only rejects others in favor of H if they like the new person better. So what we call, again this is a little messy because it's just intuition, is that recall S' only gets better and better matches, and better matches as they go on. So if S' was maybe matched with H at some point or wanted to be with someone else, that means they must have liked that someone else better than H. And whoever they eventually end up with, they must like the best out of everyone who gave the matches, which is a contradiction because we said S prime should prefer H. So this-- yeah. OK. Yeah, this intuition is a little messy. But thus, S should prefer final match. Final match H over H prime, which is a contradiction. Why is it a contradiction? Well, the instability itself says S prime should prefer H over S prime. Okay, so actually, let me just formalize this case. I'll write it down formally, and then we'll go to the other case, which is that actually Actually, no, we can do the other case because it's a little simpler. So the other case is that H never made an offer to S. But this is kind of a problem too, because H is supposed to be making offers in decreasing preference order. So if they like S prime better than S, they should have made an offer to S prime before S. So I'll just write this as a problem. age makes offers in decreasing order. So it should have made an offer to S prime before S. Made an offer to S prime before S. Okay, all right. So I'll go formalize this, but yeah. So again, this intuition is a little bit messy. Just trying to kind of get you idea of what's happening. And then we're going to formalize this. I guess any questions so far on intuition? Let me go over the intuition again. So case one, H made an offer to S prime, which we expect because H prefers S prime to S. So they probably should offer this bond before offering S anything. But S prime, if they were unmatched, they should have accepted and been with H. And the only reason that S prime would not end up with H is that someone better came along. And if someone better came along, then they'll reject H in favor of someone better. And they might reject all the way up the chain until the last person they're with should be their favorite of anyone who ever made them offer. Well, that's a problem because we assume that S prime prefers their old offer to their current match. And in the second case, we say, okay, suppose H just never made an offer to S prime, so S prime never had the chance to be their favorite bestie H. Well, that shouldn't happen because H should be making offers in their order of their preference. And if they really like S prime more than S, then why the heck did they make an offer to S without making an offer to S prime? and that's the whole intuition. So both cases, we see that something's going wrong, and therefore we're gonna say that our, but our supposing that there's instability must be incorrect, and therefore the matching is too. Okay. Questions on this intuition? Yeah, why is there an H double prime? So I'll explain that kind of when I get to the proof, but basically S prime is rejecting H in favor of someone else who may or may not be H prime. There could be a chain of people that S prime rejects before they get to H prime. So I'll put this in the proof. Okay, so with the proof. Okay, so yeah, we have a chain of people have proven, scale shapely always outputs a perfect matching. So it suffices to prove it's stable. It is stable. So we're going to say, suppose for contradiction that Gale Shapley outputs a perfect matching m that is not stable. Okay, then there we have the following, so I'll just copy it down. Okay, then we have pairs H, S and H prime, S prime, and M such that h prefers s prime to s and s prime prefers h to h prime. So we just said if it's a perfect matching then by contradiction it's not stable then here's an instability and we'll just give names to the people involved in the instability. All right. So now we're going to have case one, which is that H made an offer to S prime. And then since S prime is no longer matched to H, S prime must have rejected H in favor of some other hospital. We'll call it H double prime. So this is this diagram here. H made an offer to S prime. S prime said, no, I like some other hospital H double prime better. And then that's what happens. Okay. And then we can say, since H is part, S prime's partners only get better and better. Since S prime partners only get better and better, S prime must prefer the final partner H, H over H double prime, and thus over H prime. So let's expand this diagram out. So it could be down the line maybe S prime reject H double prime in favor of H triple prime, right? That could happen. And then there could be a whole long string of partners. And eventually, whoever they end up with, which is H, is the final one that S likes the best. So that's why we use H double prime instead of just H prime. Because it could be the case that S prime has been rejecting a ton of people and eventually ended up with H prime. So let me move this diagram up here. So yeah, we said if S prime no longer ends up with H, then they must have rejected them for someone else. And then their final partner must be their favorite after this long chain of rejections, which means that they should prefer H prime over everyone else in this list, including H double prime. And they prefer H double prime over H because they rejected H in favor of H double prime. Okay, this is a contradiction. Since we said S prefers H to H prime. So what is this contradicting? This is contradicting. Let me highlight this. contradiction here is contradicting the fact that up here we said S prefers H, S prime prefers H to H prime. That's the contradiction. Okay. Yeah, so someone asked is it necessary in both cases to be accounted for in this contradiction? The answer is yes. So imagine-- OK, so this is a side. All right. So imagine I said if x, then exit, and then else, I say, segfault or something. All right. And I want to claim that-- and I say, hey, your program can segfault. And I say, why can your program segfault? Because in this case here, a segfault occurs. This is similar to us saying, in one case, a contradiction occurs. But you could say, actually, before all this happens, I set x to be true. So even though it's possible in one case to segfault, In fact, I will never say fault because I never go to that case. So this is why you have to prove a contradiction in all cases, because even though it's possible some cases might have bad stuff happen, it could be possible that that case just never occurs, and therefore the thing that you claim is bad doesn't actually happen. So I hope that answered the question. Yes, if you put things to the cases, you have to prove a contradiction in every single case, because someone could argue that, hey, the case where you said bad stuff happened actually never occurs, and therefore your proof doesn't show anything. Okay. So, any questions on case one? All right, so let me do case two, which is H never made an offer to S prime. But we know that since S is matched to H, H made an offer to S. But H makes offers in decreasing precedence order. Preference order. So this means H prefers S to S. Okay, so right, if H makes an offer to S, but not to S', then the only way this is gonna occur is that H actually likes S more than S', because H always makes offers to their favorite people first. And this is a contradiction, because if we look at H prefers S to S', Well, up here, we said that H should prefer S prime to S. So the contradiction here, and that's this contradiction, because H was supposed to prefer S prime rather than the correct part. Okay. So there's a kind of a lot, yeah, there's previous evidence involved, is trying to kind of introduce you to some of the more complicated or some new proof techniques. At this point, we'll take a break until let's say 11.25. And you can ask me questions about these. I can scroll up. This will be posted afterward as well. Sorry, I can't show everything simultaneously. But yeah, I will pause the recording for now and then we'll resume it at 11.25. Okay, so now we've taught, we've proved that algorithm is correct. And again, this is a bit of a gnarly proof, but it's trying to get you kind of used to like seeing different ways to do proofs. And next we're going to talk about how do we actually talk about how efficient an algorithm is. So let's move down here and talk about big O notation or order notation. OK. So the first question we want to ask is, what do we mean by efficient? Right? You know, this could mean a lot of things. It could mean absolute time it takes to run. It could mean in some number of steps. It could mean how much power it uses. So if we're just talking about efficiency, there are lots of possible metrics. And for this class, we're only going to be concerned with time efficiency. So lots of possible metrics. For example, time, memory, power, et cetera. In this class, we only care about time efficiency. But this does not mean that in other instances, you're going to not care about these things. So you may be, for example, working on, say, a internet of things device that has very small hardware, very full memory, and power and memory matter a lot. So while we only care about time in this class, that does not mean these things, other things do not matter. It very much depends on your context. This kind of efficiency analysis we're doing is helping you learn how to kind of analyze things by one metric. But that doesn't mean down the line you should always ignore these other things, because they do actually matter in a lot of contexts. OK. So if we're talking about time efficiency, what we could say is that, all right, let's just time it. We'll start a stopwatch when we start running it to when we finish running it. And the one that's faster is better. Now, does anyone see any problems with just starting a stopwatch and then seeing how long it runs as a way to talk about algorithms? Yeah, someone said it's inconsistent, yes. So, yeah, hidden time cost. Yeah, so basically, if we just were to do this, yeah, it depends on hardware latency. Okay, these are all great answers. So, the problem with just running it with a stopwatch is that there's a lot inconsistencies in that a lot of how long something takes to run depends on your computer, depends on your hardware, depends on whether the operating system schedules your thing to run or not. And what could happen is I could say, "Hey, my algorithm runs faster than yours. And you look at my algorithm and I'm running it on like a five, you know, four core machine with, you know, 50 gigabytes of RAM, and you're running yours on, I don't know, a Raspberry Pi, and it's got very little memory and everything. So, it's not really fair to, you know, talk about the absolute time when all these things depend on the hardware, depend on how much power and memory you have, depend on, you know, the actual execution there. So, you know, while we actually do care about the absolute time in practice. When we want to talk about an algorithm as a thing to run, we want to have some measure of efficiency that is independent of the hardware. So we would like a measure of efficiency, which is independent in some sense of the hardware and environment in which it is run. So what we're going to do instead of saying absolute time is we're going to define it in terms of some basic step of the algorithm. Now, this is a little bit difficult because we have to say what is a basic step. But we're going to just say-- so let me just write that down first. We're going to measure that the runtime of an algorithm is the number of basic steps the algorithm takes to run. All right, but what is the basic step? OK, so here it seems like, OK, great. We're just going to look exactly what operations are run. And now this should be independent machine. But now we have to define what does it mean to be a basic step. Does a multiplication take three basic steps, or five basic steps, or one basic step? Does addition-- is that fewer basic steps than multiplication? If I say something runs for 10 steps and you say it runs for 20 steps, how do we deal with this? So what we're going to do is we're going to have this kind of vaguer notion of a basic step, but we're going to be looser on the range that it's allowed to run. So we're going to kind of say, OK, sure, maybe multiplication takes five basic steps on your machine and three basic steps on my machine, but we're not going to care about the fact that it's three or five. So we want some notion that depends on basic steps, but also it's not super concerned with the exact number. So yeah. OK, so we also want that-- OK, I won't write this down, but our notion will allow constant or constant amount-- just small differences in definitions of basic steps. Differences in defining basic steps. Okay. But pretty much for this class, what you should consider a basic step will basically be most kind of simple arithmetic operations. So for this class, a basic step is basic input/output. So reader write to the screen, write return. We're going to have reading and writing to memory. And we're also going to have basic arithmetic operations. Operations such as, you know, plus, multiply, divide, subtract, etc. Okay, so now, you know, in some cases, right, multiplication, if you're multiplying very large numbers or you're multiplying matrices, maybe you actually care about how many steps that takes, but if you're just kind of multiplying two fairly small numbers or, you know, we'll just kind of assume this is like one basic step in some sense. Yeah, so let's see more examples. For example, following a pointer. Following a pointer. Array in the same. Except, OK. So things that basically are kind of easy for you to do, but again, this is really hard to sort of define exactly what we mean by a basic step. But if something seems very complicated, then maybe you shouldn't treat it like a basic step. Or you run a sorting algorithm, right? You shouldn't just treat that as a single step. But something that kind of is built in to maybe your programming language, things that are very common, things that don't seem like they should be that hard, hopefully you can kind of consider it to be a basic step. And again, these notions might differ a little bit, but as we'll see, it won't matter quite how accurate we are. Okay. All right, so Yeah, and then one other thing we're going to talk about is, basically, in this class, we're going to only consider worst-case time efficiency. So, in this class, we only consider worst case running times. OK. So worst case running time is the time it takes if everything went wrong. So imagine you have a bunch of if conditions or you have some annoying input. The worst case running time is the running time in the worst possible case. So the input that maximizes your running time. All right. So anyone have any other ideas of notions of efficiency we could include besides worst case running time that might seem natural? >> Average? >> Yeah. Average case. So maybe you're like, okay, sure, maybe on occasion it runs for two hours, but like almost every other time it runs in 10 minutes, right? It feels like we should really only care about the most of the time that runs in 10 minutes and not really care about the fact that sometimes I guess it can run for two hours. So yeah, a very natural thing would be, you know, average case running time. And that feels like a metric that we should care about more than worst case running time if you know we care about the average probably a lot of times. Now you know certain applications. Oh yeah, so let me just write this down. So yeah, so average case runtime is a natural alternate candidate. And the reason we're not going to use average case runtime in this class is because in order to know the average case runtime, you have to know what the average case is. So this requires us to know the average case distribution. So if I want to say, oh, yeah, with my group of people who run this, on average, it does this, I have to know what are the properties that my group of people going to be using this for, right? Like, what kind of inputs are common for me to find? What kind of ways is my application being used on average? And so this can actually be quite difficult. This makes the analysis quite difficult. First, you have to gather that data, which means you need to probably do some testing or make some assumptions about what the data-- types of input you're likely to receive are. And then you have to do an analysis on that specific set of data. and that can be a lot more complex. So, average case runtime is important, but it does complicate things. And so for a lot of the cases, we're just going to stick with worst case runtime. And in fact, it turns out that in practice, worst case runtime actually works very well as a metric. So, while you might think, okay, average case is really what we want, it's our gold standard. Most algorithms that have decent worst case running times also have good average case running times. And it's sort of rare for you to kind of have some algorithms that run really well almost all the time but then have a couple of cases where they're extremely inefficient. Okay, so yeah. Just some more notes about this then. Worst-case running time generally works in practice. In practice, as a metric, most algorithms with good worst-case running time also have good average case. Average case run time. So one, it's useful and it's less. This is easier to analyze than average case. And lastly, one thing I didn't really mention yet is that some applications actually really do care about worst case. So for example, if you're flying a plane and you want to say, I want to make sure that my landing gear opens. You don't want to say, most of the time my landing gear works. You want to say, every single time my landing gear works, because it matters. People could die if your landing gear doesn't work. So some apps require good worst case running time, because if, for example, your landing gear on occasion takes three hours to deploy, that's not good, because that could be a safety issue. So, as an example, some autopilot on an airplane or other situations where it's really, really critical that no matter what occurs, nothing bad happens. OK, so this is why we're using worst case running time. One, it's easier for us to do. And the natural alternative, which is average case, is much harder to analyze, requires you to get data, requires you to do a more complicated analysis, and it's often not really necessary. Any questions on why we're talking about worst case? And then a couple other things, too, about runtime. So again, what we talked about, we care about time efficiency. We want something independent of the hardware. We're going to justify in terms of something called basic steps, which we want to be relatively flexible. And another thing we're going to do is that we're going to only care about large problems, instances. So here, when we're talking about how we're going to measure efficiency, We're going to care about how problems work on large instances, which just means lots of data. So an instance is kind of like an input. And here we care about how the problems work when you give them lots of data. And this is kind of talking about the scalability of the program. So as your data gets larger and larger, what happens? How well does it scale with more and more data? So if you're saying, well, maybe I actually care about how it runs on small data sets, well, often for those, you can actually just compute exactly how fast it will run. Or timing type things will be sufficient for that. It's really when we talk about really large instances that we don't want to actually run all these algorithms one is fastest because that will take a lot of time. So here when we're talking about the time efficiency, we're talking about scalability because oftentimes when you get to very small data, in fact, brute force approaches or even much less efficient things will be often good enough if you only have 10 items and you sort the 10 items very, very slowly. It doesn't take that long to sort 10 items even if you have a bad sorting algorithm. So we don't really care so much about how long it takes to sort 10 items. We care how long it takes to sort 100 items, a million items, 10 million items. And that's why-- yeah. OK. So with this in mind, we're now going to define what we mean. Our actual notion we'll use to talk about time efficiency. And this will be called big O notation, although the general form is ordinated. Okay, so definition, this is big O. So we say that F of N is order G of N. So this is an element of, well, I'll just write is. So a function f is big O of g, if there exists constants c greater than zero and some n zero greater than or equal to zero, such that, so I'm gonna write this down and I'll explain what this means. That such that for all large enough n n greater than equals n zero, f of n is less than c times g of n. Okay, so let me draw a diagram to explain what this means. All right, so suppose you have some function f, this is f of n, and suppose you have some other function, g of n. All right, so fn is, sorry, we'll call this c times g then. All right, so fn is big O of g if at some point, so let's say this is n0, so at some point past n0, f is always less than c times g of n. So it doesn't really matter what happens early on, we just care when n gets very large. So here this is n, and this is time, runtime. What we care about is that eventually at some point, when n gets large enough, f is always smaller than a constant times g of n. So let me write this down. This is that eventually f of n is smaller than a constant times g of n. Okay, so let's kind of talk a little bit about this. So right, so maybe you want to say that, So this is where you talk about upper bounds. So big O is used for upper bounds. So often what you'll see is an algorithm runs in big O of n squared or something, which means the algorithm takes at most n squared steps. So what we're saying is that this thing is upper bounded by g of n. It's big O of gn. It means it's upper bounded by g of n. We might think which just means that, OK, f of n is always less than g of n. But we have two caveats here. So one, we don't really care about what happens initially, because we really only care about big values of n. So allow that in the beginning, whatever can happen as long as it eventually becomes less than g of n. And two, we're allowing for it to be a constant times g of n. And the reason for this is that we don't want these constant factors to be kind of annoying. So for example, yeah, so let's say had an algorithm that ran in 5n squared steps, where n is the size of the input. Okay, and I have another algorithm that runs in, so let's say, okay let's give me the names. We'll say f is this, and we'll say h runs in 7n squared plus 3n steps, where again n is the size of the input. So the runtime will be in the size of the input. Okay, and we want to talk about these algorithms here, and so in fact what will happen is that as n gets really large, this 3n won't matter that much, and these constants here, right, they seem like they do matter some, but this might just depend on how you talk about basic steps. So, for example, maybe I define a basic, a multiplication to be one basic step, and you define the multiplication to be two basic step, and we both do, you know, n squared, actually I'm going to make this 10. Yeah, so, so the difference between 5n squared and 10n squared might be that I counted something as two basic steps and you count it as one basic step. That's one basic step. So yeah, so what could occur, right? So maybe I say the algorithm runs in 5n squared steps, you say it runs in like 10n squared steps, but actually we weren't really analyzing differently, we were just thinking, oh this thing should take one basic step, you thought it should take two, and you you know, now we get like vastly different runtimes. So we don't really actually wanna have to care about whether something should be one basic steps or two or three or four. We're just gonna say, we're gonna do away with this constant entirely. And that's not really the important part. The important part is that as n gets big, these constants will matter a lot less than the fact that there's n squares steps, you know, maybe plus some. So here, what we can say is that f of n is O of n squared. And why is this the case? It's because, because five n squared is less or equal to five, this is c, times n squared for all n bigger than zero. This is n zero. So what's happening when we're doing big O notation is we're just kind of ignoring the constant. The constant is being built in to the definition of order notation. Okay, so yeah at this point we're out of time so we'll talk a little bit more about this next time but again order notation is a way to do upper bounding on the runtime of your algorithm, in this case the worst-case runtime. And the way we're doing is we only care about big values of n and we're going to be ignoring kind of the constants here because they could be accounted for just by the fact that we don't, you know, the definition basic step is a little like, you know, wishy-washy, so we don't really have to worry about that. Okay, so at this point I'm going to end the recording. If you have any questions I'll stick around for a few minutes and then we'll have office hours again at 8 to 9 5 p.m. today.